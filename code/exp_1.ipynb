{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c4dae88c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4dae88c",
        "outputId": "0860356a-ca3d-46cb-c76e-bdc2dc736f55",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, IntervalStrategy\n",
        "import nltk\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "mEkWFpQVuSVG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEkWFpQVuSVG",
        "outputId": "028453ec-3f5a-4657-885b-0554f4dee34f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "h4yCFC3uuSVH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4yCFC3uuSVH",
        "outputId": "722d1aad-38ba-44a8-ddb4-30ee0b63ad17",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TPU/XLA обнаружен. Обучение будет использовать XLA-бэкэнд.\n"
          ]
        }
      ],
      "source": [
        "XLA_AVAILABLE = False\n",
        "try:\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    XLA_AVAILABLE = True\n",
        "    print(\"TPU/XLA обнаружен. Обучение будет использовать XLA-бэкэнд.\")\n",
        "except ImportError:\n",
        "    if torch.cuda.is_available():\n",
        "        DEVICE = torch.device(\"cuda\")\n",
        "        print(f\"CUDA обнаружена. Используемое устройство: {DEVICE}\")\n",
        "    else:\n",
        "        DEVICE = torch.device(\"cpu\")\n",
        "        print(f\"CUDA не найдена. Используемое устройство: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "YeHZTlkruSVO",
      "metadata": {
        "id": "YeHZTlkruSVO",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class SpellingCorrectionDataset(TorchDataset):\n",
        "    \"\"\"Класс Pytorch Dataset для работы с Pandas DataFrame.\"\"\"\n",
        "    def __init__(self, dataframe, tokenizer, max_length=64):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "        self.input_texts = self.data['input_text'].tolist()\n",
        "        self.target_texts = self.data['target_text'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_text = self.input_texts[index]\n",
        "        target_text = self.target_texts[index]\n",
        "\n",
        "        input_encoding = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_encoding = self.tokenizer(\n",
        "            text_target=target_text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encoding['input_ids'].flatten(),\n",
        "            'attention_mask': input_encoding['attention_mask'].flatten(),\n",
        "            'labels': target_encoding['input_ids'].flatten()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871ba5b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "871ba5b5",
        "outputId": "15d19668-734e-40a5-f1d4-0ca195e593ad",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Полные данные загружены: Train=38856, Val=4857, Test=4857\n",
            "Данные загружены: Train=3885, Val=485, Test=485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение в 3 эпох\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='729' max='729' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [729/729 03:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.155700</td>\n",
              "      <td>0.141744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.134988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>0.132068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Тестирование: 100%|██████████| 485/485 [08:58<00:00,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CER НА ТЕСТОВОМ ДАТАСЕТЕ: 0.3971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    FULL_TRAIN_DF = pd.read_csv(\"./train_words.csv\")\n",
        "    FULL_VAL_DF = pd.read_csv(\"./val_words.csv\")\n",
        "    FULL_TEST_DF = pd.read_csv(\"./test_words.csv\")\n",
        "\n",
        "    print(f\"Полные данные загружены: Train={len(FULL_TRAIN_DF)}, Val={len(FULL_VAL_DF)}, Test={len(FULL_TEST_DF)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Ошибка: CSV файлы датасета не найдены.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "TRAIN_DF = FULL_TRAIN_DF.sample(n=int(len(FULL_TRAIN_DF) * 0.1), random_state=42).reset_index(drop=True)\n",
        "VAL_DF = FULL_VAL_DF.sample(n=int(len(FULL_VAL_DF) * 0.1), random_state=42).reset_index(drop=True)\n",
        "TEST_DF = FULL_TEST_DF.sample(n=int(len(FULL_TEST_DF) * 0.1), random_state=42).reset_index(drop=True)\n",
        "print(f\"Данные загружены: Train={len(TRAIN_DF)}, Val={len(VAL_DF)}, Test={len(TEST_DF)}\")\n",
        "\n",
        "model_name = \"cointegrated/rut5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "if not XLA_AVAILABLE:\n",
        "    model.to(DEVICE)\n",
        "\n",
        "\n",
        "train_dataset = SpellingCorrectionDataset(TRAIN_DF, tokenizer)\n",
        "val_dataset = SpellingCorrectionDataset(VAL_DF, tokenizer)\n",
        "EST_DF = FULL_TEST_DF.sample(n=len(FULL_TEST_DF)//10, random_state=42)\n",
        "\n",
        "NUM_EPOCHS_TEST = 3\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=IntervalStrategy.EPOCH,\n",
        "    save_strategy=IntervalStrategy.EPOCH,\n",
        "\n",
        "    optim=\"adamw_torch\",\n",
        "\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=NUM_EPOCHS_TEST,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "print(f\"Обучение в {NUM_EPOCHS_TEST} эпох\")\n",
        "trainer.train()\n",
        "\n",
        "output_dir = \"./\"\n",
        "\n",
        "model.save_pretrained(output_dir, safe_serialization=False)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "def calculate_cer(reference, hypothesis):\n",
        "    reference = reference.replace(' ', '')\n",
        "    hypothesis = hypothesis.replace(' ', '')\n",
        "    if len(reference) == 0:\n",
        "        return 0.0\n",
        "    return nltk.edit_distance(reference, hypothesis) / len(reference)\n",
        "\n",
        "def correct_word(input_word_only, current_model, current_tokenizer):\n",
        "    prefixed_text = 'fix spelling: ' + input_word_only\n",
        "    inputs = current_tokenizer(prefixed_text, return_tensors=\"pt\", max_length=64, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_device = current_model.device\n",
        "    input_ids = inputs.input_ids.to(model_device)\n",
        "    attention_mask = inputs.attention_mask.to(model_device)\n",
        "    if XLA_AVAILABLE and model_device.type == 'xla':\n",
        "        with torch.no_grad():\n",
        "            outputs = current_model.generate(\n",
        "                input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=64,\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "            ).cpu()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            outputs = current_model.generate(\n",
        "                input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=64,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "    return current_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "\n",
        "total_cer = 0\n",
        "N = len(TEST_DF)\n",
        "\n",
        "\n",
        "test_data_for_eval = TEST_DF.to_dict('records')\n",
        "\n",
        "for row in tqdm(test_data_for_eval, desc=\"Тестирование\"):\n",
        "    target = row['target_text']\n",
        "    input_word_only = row['input_text'].replace('fix spelling: ', '')\n",
        "    predicted = correct_word(input_word_only, model, tokenizer)\n",
        "    current_cer = calculate_cer(target, predicted)\n",
        "    total_cer += current_cer\n",
        "\n",
        "final_cer = total_cer / N\n",
        "print(f\"CER НА ТЕСТОВОМ ДАТАСЕТЕ: {final_cer:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
