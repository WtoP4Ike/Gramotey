# Нейросетевой Корректор ошибок в словах, написанных на Русском Языке 

<h1>Описание проекта</h1>
<h2>Цель</h2>

> Целью данного проекта является создание модели для автоматического исправления орфографических ошибок и опечаток на русском языке отдельных слов.
<h2>Архитектура модели</h2>

> Используется модель-трансформер T5 (Text-to-Text Transfer Transformer), которая изначально разработана для преобразования текста в текст.
> Задача сформулирована как Sequence-to-Sequence (Seq2Seq): модель получает на вход строку с префиксом (fix spelling: [слово с ошибкой]) и должна сгенерировать правильное слово ([правильное слово]).
> Модель rut5-small была выбрана как сбалансированное решение, позволяющее достичь высокой точности при относительно быстром обучении.
<h2>Датасеты</h2>
<h3>Структура</h3>

> Для обучения модели использовался синтетический набор данных, который был разделён на три файла: train_words.csv, val_words.csv и test_words.csv.
>
> train_words.csv (38857 строк):
> Используется для непосредственного обучения модели
>
> val_words.csv (4858 строк):
> Используется для оценки прогресса и настройки гиперпараметров после каждой эпохи.
>
> test_words.csv (4858 строк):
> Датасет для финальной оценки модели.
> 
> Датасет состоит из пар "опечатка -> исправление"
>
> Варианты ошибок:
> Замена: даброму -> доброму.
> Замена на клавишу, расположенную рядом на клавиатуре: пртвет -> привет
> Перестановка: актаульно -> актуально.
> Ошибки раскладки: hfpjhznm -> разорять
> 
> Код генерации датасета: 
> В качестве основы датасета взято произведение Льва Николаевича Толстого
>
<h2>Результаты</h2>
<h3>Loss:</h3>

> Эпоха 1: 0.115100 (Training Loss), 0.090237 (Validation Loss).
> Эпоха 2: 0.091400 (Training Loss), 0.073965 (Validation Loss).
> Эпоха 3: 0.080200 (Training Loss), 0.069983 (Validation Loss).
<h3>Финальная метрика качества (CER)</h3>

> Значение: 0.1839
> Данное значение можно легко уменьшить, путем увеличения количества эпох обучения до 8-10. В рамках данного проекта это не сделано из-за ограничений мощностей. В результате значение может упасть примерно до 0.09.
<h1>Инструкция по запуску</h1>

> Скачайте папку model. Установите зависимости из файла requirements.txt (pip install -r requirements.txt). Запустите код run.py.


<h1>Метрики</h1>
<h2>Описание метрик</h2>

> Оценка качества модели производится с помощью двух ключевых метрик: Loss (Потери) и CER (Character Error Rate - Ошибка символов). 
<h3>Loss</h3>

> Оценивает, насколько вероятностное распределение предсказаний модели совпадает с фактическим целевым распределением. В нашем случае используется Cross-Entropy Loss, стандартный для Seq2Seq задач.
<h3>CER (Character Error Rate — Ошибка символов)</h3>

> Оценивает конечный результат. Насколько предсказанное слово совпадает с целевым, независимо от вероятностей.