# Нейросетевой Корректор ошибок в словах, написанных на Русском Языке 

<h1>Описание проекта</h1>

<h2>Цель</h2>

> Целью данного проекта является создание модели для автоматического исправления орфографических ошибок и опечаток на русском языке отдельных слов.

<h2>Архитектура модели</h2>

> В качестве базовой архитектуры выбрана модель T5 (Text-to-Text Transfer Transformer), которая изначально разработана для преобразования текста в текст.
> Задача для модели сформулирована как "Text-to-Text": на вход подается искаженное слово, на выходе ожидается исправленный вариант.
> Модель rut5-small была выбрана как сбалансированное решение, позволяющее достичь высокой точности при относительно быстром обучении.
> Tokenizer: T5Tokenizer.
> Оптимизатор: AdamW.

<h2>Датасеты</h2>
<h3>Структура</h3>

> Для обучения модели использовался синтетический набор данных, который был разделён на три файла: train_words.csv, val_words.csv и test_words.csv.
>
> train_words.csv (38857 строк):
> Используется для непосредственного обучения модели
>
> val_words.csv (4858 строк):
> Используется для оценки прогресса и настройки гиперпараметров после каждой эпохи.
>
> test_words.csv (4858 строк):
> Датасет для финальной оценки модели.
> 
> Датасет состоит из пар "опечатка -> исправление"
>
> Варианты ошибок:
> Замена: даброму -> доброму.
> Замена на клавишу, расположенную рядом на клавиатуре: пртвет -> привет
> Перестановка: актаульно -> актуально.
> Ошибки раскладки: hfpjhznm -> разорять
> 
> Код генерации датасета: 
> В качестве основы датасета взято произведение Льва Николаевича Толстого





<h1>Метрики</h1>
<h2>Описание метрик</h2>

> Оценка качества модели производится с помощью двух ключевых метрик: Loss (Потери) и CER (Character Error Rate - Ошибка символов). 
<h3>Loss</h3>

> Оценивает, насколько вероятностное распределение предсказаний модели совпадает с фактическим целевым распределением. В нашем случае используется Cross-Entropy Loss, стандартный для Seq2Seq задач.
<h3>CER (Character Error Rate — Ошибка символов)</h3>

> Оценивает конечный результат. Насколько предсказанное слово совпадает с целевым, независимо от вероятностей.









<h1>Эксперементы и обучение</h1>

<h2>Эксперемент 1</h2>
<h3>Конфигурация</h3>

> 3 эпохи, сокращенный датасет (subset).

<h3>Метрики</h3>

> Final Validation Loss: 0.1321.
> Test CER: 0.3971 (39.7% ошибок).

<h3>Анализ</h3>

> Модель демонстрирует явное недообучение. Высокий CER говорит о том, что модель часто ошибается даже в простых словах.

<h3>Графики</h3>

ФОТО

> Сравнение метрик

ФОТО

> График прогрессирования метрик


<h2>Эксперемент 2</h2>
<h3>Измения по сравнению с эксперементом 1</h3>

> Использован полный набор данных (все 38 тыс. примеров).

<h3>Метрики</h3>

> Final Validation Loss: 0.0697 (УМЕНЬШИЛСЯ НА 47% ПО СРАВНЕНИЮ С ПЕРВЫМ ЭКСПЕРЕМЕНТОМ).
> Test CER: 0.1810 (УМЕНЬШИЛСЯ НА 54% ПО СРАВНЕНИЮ С ПЕРВЫМ ЭКСПЕРЕМЕНТОМ).

<h3>Анализ</h3>

> Увеличение объема данных дало зачительный прирост качества. Однако динамика Loss на 3-й эпохе показывала, что потенциал модели еще не исчерпан.

<h3>Графики</h3>

> ФОТО

> Сравнение метрик

> ФОТО

> График прогрессирования метрик



<h2>Эксперемент 3</h2>
<h3>Измения по сравнению с эксперементом 2</h3>

> Количество эпох обучения

<h3>Метрики</h3>

> Final Validation Loss: 0.0697 (УМЕНЬШИЛСЯ НА 25%)
> Test CER: 0.12 (УМЕНЬШИЛСЯ НА 31%)

<h3>Анализ</h3>

> Увеличение количества эпох дало хороший прирост качества.

<h3>Графики</h3>

> ФОТО

> Сравнение метрик

> ФОТО

> График прогрессирования метрик

<h2>Итоговое сравнение</h2>

> График итогового сравнения


<h1>Финальные результаты</h1>
<h2>Результаты</h2>

> Test CER: 0.1234 (только 12.34% символов в сгенерированных словах не совпадают с эталоном).
> Final Validation Loss: 0.0517.
> Время обучения: 1,5 часа (на GPU).


<h1>Примеры работы</h1>

> 
> Фото
> 

<h1>Инструкция по запуску</h1>

> Скачайте папку model. Установите зависимости из файла requirements.txt (pip install -r requirements.txt). Запустите код run.py.

