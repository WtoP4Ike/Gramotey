# Нейросетевой Корректор ошибок в словах, написанных на Русском Языке 

<h1>Описание проекта</h1>

<h2>Цель</h2>

> Целью данного проекта является создание модели для автоматического исправления орфографических ошибок и опечаток на русском языке отдельных слов.

<h2>Архитектура модели</h2>

> В качестве базовой архитектуры выбрана модель T5 (Text-to-Text Transfer Transformer), которая изначально разработана для преобразования текста в текст.
> Задача для модели сформулирована как "Text-to-Text": на вход подается искаженное слово, на выходе ожидается исправленный вариант.
> Модель rut5-small была выбрана как сбалансированное решение, позволяющее достичь высокой точности при относительно быстром обучении.
> Tokenizer: T5Tokenizer.
> Оптимизатор: AdamW.

<h2>Датасеты</h2>
<h3>Структура</h3>

> Для обучения модели использовался синтетический набор данных, который был разделён на три файла: train_words.csv, val_words.csv и test_words.csv.
>
> train_words.csv (38857 строк):
> Используется для непосредственного обучения модели
>
> val_words.csv (4858 строк):
> Используется для оценки прогресса и настройки гиперпараметров после каждой эпохи.
>
> test_words.csv (4858 строк):
> Датасет для финальной оценки модели.
> 
> Датасет состоит из пар "опечатка -> исправление"
>
> Варианты ошибок:
> Замена: даброму -> доброму.
> Замена на клавишу, расположенную рядом на клавиатуре: пртвет -> привет
> Перестановка: актаульно -> актуально.
> Ошибки раскладки: hfpjhznm -> разорять
> 
> Код генерации датасета: 
> В качестве основы датасета взято произведение Льва Николаевича Толстого





<h1>Метрики</h1>
<h2>Описание метрик</h2>

> Оценка качества модели производится с помощью двух ключевых метрик: Loss (Потери) и CER (Character Error Rate - Ошибка символов). 
<h3>Loss</h3>

> Оценивает, насколько вероятностное распределение предсказаний модели совпадает с фактическим целевым распределением. В нашем случае используется Cross-Entropy Loss, стандартный для Seq2Seq задач.
<h3>CER (Character Error Rate — Ошибка символов)</h3>

> Оценивает конечный результат. Насколько предсказанное слово совпадает с целевым, независимо от вероятностей.









<h1>Эксперементы и обучение</h1>

<h2>Эксперемент 1</h2>
<h3>Конфигурация</h3>

> 3 эпохи, сокращенный датасет (subset).

<h3>Метрики</h3>

> Final Validation Loss: 0.1321.
> Test CER: 0.3971 (39.7% ошибок).

<h3>Анализ</h3>

> Модель демонстрирует явное недообучение. Высокий CER говорит о том, что модель часто ошибается даже в простых словах.

<h3>Графики</h3>

> <img width="989" height="590" alt="image" src="https://github.com/user-attachments/assets/24ba7a80-5661-4e03-9354-13f04216a61a" />
> Сравнение метрик
>
> <img width="1628" height="813" alt="image" src="https://github.com/user-attachments/assets/3c7935da-f3c1-4c7e-a3d8-4f5ab749a17f" />
> График прогрессирования метрик


<h2>Эксперемент 2</h2>
<h3>Измения по сравнению с эксперементом 1</h3>

> Использован полный набор данных (все 38 тыс. примеров).

<h3>Метрики</h3>

> Final Validation Loss: 0.0697 (УМЕНЬШИЛСЯ НА 47% ПО СРАВНЕНИЮ С ПЕРВЫМ ЭКСПЕРЕМЕНТОМ).
> Test CER: 0.1810 (УМЕНЬШИЛСЯ НА 54% ПО СРАВНЕНИЮ С ПЕРВЫМ ЭКСПЕРЕМЕНТОМ).

<h3>Анализ</h3>

> Увеличение объема данных дало зачительный прирост качества. Однако динамика Loss на 3-й эпохе показывала, что потенциал модели еще не исчерпан.

<h3>Графики</h3>

> <img width="989" height="590" alt="image" src="https://github.com/user-attachments/assets/bfd90a7b-cce7-4f65-b1f9-9ce432df5e5f" />
> Сравнение метрик
> 
> <img width="1638" height="841" alt="image" src="https://github.com/user-attachments/assets/b3c4c99b-7817-4b1a-a261-c2e0ab30b016" />
> График прогрессирования метрик



<h2>Эксперемент 3</h2>
<h3>Измения по сравнению с эксперементом 2</h3>

> Количество эпох обучения

<h3>Метрики</h3>

> Final Validation Loss: 0.0697 (УМЕНЬШИЛСЯ НА 25%)
> Test CER: 0.12 (УМЕНЬШИЛСЯ НА 31%)

<h3>Анализ</h3>

> Увеличение количества эпох дало хороший прирост качества.

<h3>Графики</h3>

> <img width="989" height="590" alt="image" src="https://github.com/user-attachments/assets/72b64aef-a44e-4056-8734-f91af1bca11f" />
> Сравнение метрик
> 
> <img width="1636" height="863" alt="image" src="https://github.com/user-attachments/assets/70508e97-b6ca-4300-b1f9-cc48061adf5d" />
> График прогрессирования метрик


<h2>Итоговое сравнение</h2>

> <img width="1628" height="849" alt="image" src="https://github.com/user-attachments/assets/834b4fc3-f995-4196-af8c-9f1032ee674e" />
> График итогового сравнения


<h1>Финальные результаты</h1>
<h2>Результаты</h2>

> Test CER: 0.1234 (только 12.34% символов в сгенерированных словах не совпадают с эталоном).
> Final Validation Loss: 0.0517.
> Время обучения: 1,5 часа (на GPU).


<h1>Примеры работы</h1>

> <img width="397" height="682" alt="image" src="https://github.com/user-attachments/assets/047447ff-ed53-4be3-80cd-00974f7990e2" />


<h1>Инструкция по запуску</h1>

> Скачайте папку model. Установите зависимости из файла requirements.txt (pip install -r requirements.txt). Запустите код run.py.

